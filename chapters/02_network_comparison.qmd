---
execute: 
  warning: false
---

# Dealing with multiple data sets: consensus modules and module preservation

In this lesson, you will learn how to compare coexpression networks to 
identify preserved modules. At the end of the lesson, you will be able to:

- understand the concept of and identify consensus modules across data sets
- associate consensus modules to traits
- calculate module preservation statistics

Let's start by loading the packages we will use.

```{r}
set.seed(123) # for reproducibility

# Load required packages
library(tidyverse)
library(BioNERO)
library(SummarizedExperiment)
library(here)
```

## Getting to know the example data

In this chapter, we will use gene expression data from two BioProjects:


1. **PRJNA800609**: soybean pods infected with the 
fungus *Colletotrichum truncatum*. Original data generated 
by @zhu2022transcriptomic.

2. **PRJNA574764**: soybean roots infected with the 
oomycete *Phytophthora sojae*. Original data generated by @de2020integrated.


Our goal here is to explore similarities and differences in expression
profiles between these two data sets.


Data are available as *.rda* files in the `data/` directory
of the 
[GitHub repo associated with this course](https://github.com/almeidasilvaf/NASB),
and they were downloaded from 
[The Soybean Expression Atlas v2](https://soyatlas.venanciogroup.uenf.br/)
[@almeida2023soybean] by searching by BioProject IDs. These *.rda* files contain 
`SummarizedExperiment` objects that store gene expression data and sample
metadata.


Let's load the data and explore them briefly.

```{r}
# Load expression data
load(here("data", "se_PRJNA800609.rda"))
load(here("data", "se_PRJNA574764.rda"))

# Rename object to a simpler name
exp1 <- se_PRJNA800609
exp2 <- se_PRJNA574764

rm(se_PRJNA800609)
rm(se_PRJNA574764)

# Take a look at the object
exp1
exp2

colData(exp1)
colData(exp2)
```


::: {.callout-tip}

### Practice

1. Explore the sample metadata of `exp1` and `exp2` and answer the questions 
below:

- How many different cultivars are there?
- What are the levels of the `Treatment` variable, and how many samples
are there for each level?
- How many samples are there for each timepoint?

::: {.callout-tip appearance="minimal" collapse="true"}

### Show me the solutions

```{r}
# Question 1: # of cultivars
length(unique(exp1$Cultivar))
length(unique(exp2$Cultivar))

# Question 2: levels of the `Treatment` variable
table(exp1$Treatment)
table(exp2$Treatment)

# Question 3: # of samples for each timepoint
table(exp1$Timepoint)
table(exp2$Timepoint)
```

:::

:::


## Data preprocessing

Now, we will preprocess the two data sets using the same
parameters with `exp_preprocess()`. In details, we will:

1. Keep only genes with median TPM >=5.
2. Keep only the top 10k genes with the highest variances.


```{r}
# Store each expression data in a list, each data set in a list element
exp_list <- list(                      # <1>
    colletrotrichum_infection = exp1,  # <1>
    phytophthora_infection = exp2      # <1>
)                                      # <1>

# Loop through the list and preprocess data
exp_list <- lapply(                                                       # <2>
    exp_list,                                                             # <2>
    exp_preprocess,                                                       # <3>
    min_exp = 5, variance_filter = TRUE, n = 1e4, Zk_filtering = FALSE    # <4>
)

# Keep only genes that are shared between the two sets
shared <- intersect(
    rownames(exp_list$colletrotrichum_infection),
    rownames(exp_list$phytophthora_infection)
)

exp_list <- lapply(exp_list, function(x) x[shared, ])
```
1. Store each expression data set in a list element.
2. Loop through each element of the list `exp_list`, and
3. execute the function `exp_preprocess`,
4. using these parameters.


Now, we have a list of processed expression data. This list, with each element
representing a different data set, is what we will use for all network
comparison functions in the next sections.

::: {.callout-tip}

### Practice

1. How many genes and samples are there in each processed data?

2. If we selected the top 10k genes with the highest variances, why do we
not have 10k genes in each final set?

::: {.callout collapse="true" appearance="minimal"}

### Show me the solutions

```{r}
# Q1
sapply(exp_list, nrow)
sapply(exp_list, ncol)

#' Q2: the genes with the highest variances are not the same in both sets.
#' Thus, when filtering the data to keep only shared genes, some genes are
#' removed.
```

:::
:::

## Identifying and analyzing consensus modules

Consensus modules are coexpression modules present in different, independent
data sets, and they can used to find robust modules across data sets that
study the same (or similar) conditions.

To identify them, __BioNERO__ infers a GCN for each data set and looks for
groups of genes that are densely connected in all data sets. Thus, the workflow
here will be very similar to what we did in the previous lesson. We will:

1. Identify the optimal $\beta$ power to which correlations will be raised
(see previous chapter for more details on why this is done), but for each
individual data set - `consensus_SFT_fit()`
2. Infer GCNs and identify consensus modules - `consensus_modules()`.

Let's obtain the $\beta$ powers.

```{r}
# Identify the optimal beta power for each data set
sfts <- consensus_SFT_fit(
    exp_list = exp_list,
    setLabels = names(exp_list),
    cor_method = "pearson"
)

sfts$power
sfts$plot
```

Next, let's find consensus modules.

```{r}
# Find consensus modules
consensus <- consensus_modules(
    exp_list, 
    power = sfts$power,
    cor_method = "pearson"
)

# Taking a look at the consensus modules
plot_dendro_and_colors(consensus)

# Inspecting the output
names(consensus)
```

As you may have noticed, the output of `consensus_modules()` is very similar
to the output of `exp2gcn()`. The output object is a list containing the
following elements:

1. `consMEs`: list with consensus module eigengenes.
2. `exprSize`: list with number of data sets, and number of genes and samples
for each set.
3. `sampleInfo`: list of data frames with sample metadata.
4. `genes_cmodules`: data frame with genes and their corresponding consensus
modules.
5. `dendro_plot_objects`: objects for plotting with `plot_dendro_and_colors()`.


::: {.callout-tip}

### Practice

Explore the output of `consensus_modules()` and answer the following questions:

1. How many consensus modules were identified between the two data sets?
2. What are the largest and the smallest consensus modules?
3. What is the mean and median number of genes per consensus modules?


::: {.callout collapse="true" appearance="minimal"}

### Show me the solutions

```{r}
# Q1
length(unique(consensus$genes_cmodules$Cons_modules))

# Q2
sort(table(consensus$genes_cmodules$Cons_modules))

# Q3
mean(table(consensus$genes_cmodules$Cons_modules))
median(table(consensus$genes_cmodules$Cons_modules))
```

:::

:::

Next, you'd want to find correlations between consensus modules and traits of
interest. Here, we will look for associations between consensus modules and
the `Treatment` variable. Biologically speaking, we're looking for shared
transcriptional responses during infection with *Colletotrichum truncatum* and
*Phytophthora sojae* (i.e., core immunity-related coexpression modules).

```{r fig.width=5, fig.height=6}
#| fig-width: 5
#| fig-height: 6

# Correlate consensus modules to traits
consensus_trait <- consensus_trait_cor(
    consensus,
    metadata_cols = "Treatment"
)

# Taking a look at the output
head(consensus_trait)

# Plot consensus module-trait correlations
plot_module_trait_cor(consensus_trait)
```

::: {.callout-tip}

### Practice

Explore the output of `consensus_trait_cor()` and answer the questions below:

1. Which consensus module has the highest positive correlation to the *infected*
status of the `Treatment` variable?

2. Which consensus module has the highest negative correlation to the *infected*
status of the `Treatment` variable?

3. (Advanced) Based on your biological knowledge, what gene functions would 
you expect to find in the modules you found in questions 1 and 2?

::: {.callout collapse="true" appearance="minimal"}

### Show me the solutions

```{r}
# Q1
cor_infected <- consensus_trait[consensus_trait$trait == "infected", ]
cor_infected[which.max(cor_infected$cor), ]

# Q2
cor_infected[which.min(cor_infected$cor), ]
```

:::
:::


::: {.callout-warning icon="false"}

### Challenge

Use the function `module_enrichment()` to perform a functional enrichment
analysis for each consensus module. Then, try to interpret the results in
light of the consensus module-trait associations you found previously.

Tip: to load the functional annotation data, use the following:

```{r}
#| eval: false
load(here("data", "gma_annotation.rda"))
```

::: {.callout collapse="true" appearance="minimal"}

### Show me the solutions

```{r}
# Load functional annotation data
load(here("data", "gma_annotation.rda"))

# Define background
background <- rownames(exp_list$colletrotrichum_infection)
    
# Perform the enrichment analysis
sim_net <- consensus
names(sim_net)[4] <- "genes_and_modules"
names(sim_net$genes_and_modules) <- c("Genes", "Modules")

enrich_mapman <- module_enrichment(sim_net, background, gma_annotation$MapMan)
enrich_interpro <- module_enrichment(sim_net, background, gma_annotation$InterPro)
```

:::
:::


## Calculating module preservation statistics

When we infer consensus modules across data sets, we only consider shared
modules, but we have no information on which modules are **not shared** between
different data sets. 

If you want to have a more detailed picture of which modules are preserved 
and which are not, you'd need to infer a separate network for each data set,
and then calculate module preservation statistics between the networks.

Here, we will demonstrate how to do that using the same data set from
the previous section. Since, we already have the processed data, we will
proceed to GCN inference using the functions `SFT_fit()` and `exp2gcn()`,
as we saw in Chapter 1.

```{r}
# Get optimal beta power for each data set
powers <- lapply(exp_list, SFT_fit, cor_method = "pearson")

# Infer GCN for each data set
gcns <- lapply(seq_along(powers), function(n) {
    
    gcn <- exp2gcn(
        exp_list[[n]], 
        SFTpower = powers[[n]]$power, 
        cor_method = "pearson"
    )
    
    return(gcn)
})
```

::: {.callout-tip}

### Practice

How many modules are there in each network?

::: {.callout collapse="true" appearance="minimal"}

### Show me the solutions

```{r}
sapply(gcns, function(x) length(unique(x$genes_and_modules$Modules)))
```

:::
:::

Next, we can calculate module preservation statistics using the 
permutation-based approach implemented in `r BiocStyle::CRANpkg("NetRep")`.

```{r}
# Calculate module preservation statistics
pres_netrep <- module_preservation(
    exp_list, 
    ref_net = gcns[[1]], 
    test_net = gcns[[2]], 
    algorithm = "netrep"
)

# Taking a look at the P-values for preservation statistics for each module
head(pres_netrep$p.values)
```

Note that, to calculate module preservation statistics, you always need to
choose a **reference network** and a **test network**. Thus, the function
`module_preservation()` will return which modules of the reference network that
are preserved in the test network. 

Careful readers will also notice that this is another major difference between identifying consensus modules and calculating module preservation statistics:
one can identify consensus modules across any number of data sets, but
module preservation statistics can only be calculated in a pairwise manner.


::: {.callout-tip icon="false"}

### Practice

1. By default, __BioNERO__ considers modules to be preserved if all preservation
statistics ($N=7$) are significant ($P<0.05$). Suppose you want to be less 
stringent and consider modules as preserved if 5 or more statistics are
significant. Would the number of preserved modules change? Verify that.

2. Use the function `module_enrichment()` to find enriched functions in all
modules of the reference network. Then, explore the enriched functions of 
preserved modules (if any).

::: {.callout appearance="minimal" collapse="true"}

### Show me the solutions

```{r}
# Q1
## Extract significant statistics for each module
sig_stats <- apply(pres_netrep$p.values, 1, function(x) x[x < 0.05])
sig_stats

## Keep only modules with 5+ significant stats
sig_stats[lengths(sig_stats) >= 5]


# Q2
background <- rownames(exp_list[[1]])
enrich_preserved <- module_enrichment(
    gcns[[1]],
    background_genes = background,
    annotation = gma_annotation$MapMan
)
```

:::
:::


## Session information {.unnumbered}

This chapter was created under the following conditions:

```{r}
#| echo: false
sessioninfo::session_info()
```

## References {.unnumbered}


